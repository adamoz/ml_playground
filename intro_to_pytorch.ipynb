{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6622, 0.1148, 0.8905, 0.6815],\n",
       "        [0.1778, 0.3767, 0.6672, 0.8088],\n",
       "        [0.8123, 0.7168, 0.8233, 0.0852],\n",
       "        [0.9552, 0.5699, 0.5575, 0.4409],\n",
       "        [0.7661, 0.3184, 0.2364, 0.6215]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1635, 0.8862, 0.3673, 0.2578],\n",
       "        [0.4794, 0.2664, 0.6679, 0.9998],\n",
       "        [0.5770, 0.4683, 0.5257, 0.0643],\n",
       "        [0.5916, 0.3146, 0.1784, 0.0361],\n",
       "        [0.3267, 0.2900, 0.1372, 0.4784]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5, 4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.1635279655456543,\n",
       "  0.8862454891204834,\n",
       "  0.36734676361083984,\n",
       "  0.2578318119049072]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tolist()[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16352797,  0.88624549,  0.36734676,  0.25783181],\n",
       "       [ 0.47940516,  0.2664358 ,  0.6679309 ,  0.99979913],\n",
       "       [ 0.57697415,  0.46834332,  0.52573955,  0.06427157],\n",
       "       [ 0.59158486,  0.31462371,  0.17836815,  0.03613251],\n",
       "       [ 0.32673222,  0.28996468,  0.13719589,  0.47843015]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "x = x.to(device)\n",
    "xx = x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grad setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([3, 1], requires_grad=True, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 3.], grad_fn=<AddBackward>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25.9221,  9.5707]], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * y + torch.rand(1, 2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.requires_grad_(True)\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7464, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = z.mean()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  6.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient is cumulative\n",
    "x.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join existing gradinet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50., 30.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3, 1], requires_grad=True, dtype=torch.float)\n",
    "y = x + 2\n",
    "z = y * y + torch.rand(1, 2)\n",
    "out = z.mean()\n",
    "\n",
    "\n",
    "ready_gradient = torch.tensor(10, dtype=torch.float)\n",
    "out.backward(ready_gradient)\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning of gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25875530.0\n",
      "1 23477310.0\n",
      "2 25139320.0\n",
      "3 27555168.0\n",
      "4 27564088.0\n",
      "5 23420998.0\n",
      "6 16451155.0\n",
      "7 9805631.0\n",
      "8 5341537.5\n",
      "9 2906914.0\n",
      "10 1697768.5\n",
      "11 1101633.5\n",
      "12 791485.4375\n",
      "13 614261.4375\n",
      "14 501464.375\n",
      "15 422042.125\n",
      "16 361631.96875\n",
      "17 313463.40625\n",
      "18 273781.5625\n",
      "19 240483.578125\n",
      "20 212181.75\n",
      "21 187912.453125\n",
      "22 166969.3125\n",
      "23 148792.421875\n",
      "24 132967.484375\n",
      "25 119103.7265625\n",
      "26 106923.9140625\n",
      "27 96194.8671875\n",
      "28 86710.875\n",
      "29 78309.203125\n",
      "30 70847.8984375\n",
      "31 64203.12890625\n",
      "32 58277.8046875\n",
      "33 52987.87890625\n",
      "34 48246.3359375\n",
      "35 43989.8359375\n",
      "36 40159.37890625\n",
      "37 36705.375\n",
      "38 33587.5390625\n",
      "39 30768.173828125\n",
      "40 28215.33984375\n",
      "41 25899.32421875\n",
      "42 23798.056640625\n",
      "43 21887.525390625\n",
      "44 20148.19140625\n",
      "45 18563.166015625\n",
      "46 17116.125\n",
      "47 15794.2216796875\n",
      "48 14584.9150390625\n",
      "49 13477.3095703125\n",
      "50 12462.15625\n",
      "51 11531.015625\n",
      "52 10676.0341796875\n",
      "53 9890.4248046875\n",
      "54 9168.173828125\n",
      "55 8503.908203125\n",
      "56 7891.564453125\n",
      "57 7327.599609375\n",
      "58 6807.47607421875\n",
      "59 6327.38720703125\n",
      "60 5883.56494140625\n",
      "61 5473.40625\n",
      "62 5094.298828125\n",
      "63 4743.447265625\n",
      "64 4418.59765625\n",
      "65 4118.04248046875\n",
      "66 3840.3115234375\n",
      "67 3582.994873046875\n",
      "68 3344.468994140625\n",
      "69 3123.384033203125\n",
      "70 2918.260986328125\n",
      "71 2727.486083984375\n",
      "72 2550.072021484375\n",
      "73 2385.092529296875\n",
      "74 2231.513671875\n",
      "75 2088.533203125\n",
      "76 1955.3570556640625\n",
      "77 1831.36279296875\n",
      "78 1715.881591796875\n",
      "79 1607.989013671875\n",
      "80 1507.3253173828125\n",
      "81 1413.40625\n",
      "82 1325.698486328125\n",
      "83 1243.8126220703125\n",
      "84 1167.313720703125\n",
      "85 1095.8116455078125\n",
      "86 1028.990966796875\n",
      "87 966.4896850585938\n",
      "88 908.0144653320312\n",
      "89 853.3182983398438\n",
      "90 802.0968017578125\n",
      "91 754.10302734375\n",
      "92 709.1716918945312\n",
      "93 667.0533447265625\n",
      "94 627.57421875\n",
      "95 590.5653686523438\n",
      "96 555.8517456054688\n",
      "97 523.286865234375\n",
      "98 492.7332763671875\n",
      "99 464.0586853027344\n",
      "100 437.15765380859375\n",
      "101 411.88555908203125\n",
      "102 388.15301513671875\n",
      "103 365.8660888671875\n",
      "104 344.9092712402344\n",
      "105 325.2077941894531\n",
      "106 306.6868591308594\n",
      "107 289.2691650390625\n",
      "108 272.9011535644531\n",
      "109 257.49310302734375\n",
      "110 242.9962158203125\n",
      "111 229.3504638671875\n",
      "112 216.51072692871094\n",
      "113 204.4259490966797\n",
      "114 193.04531860351562\n",
      "115 182.32608032226562\n",
      "116 172.2309112548828\n",
      "117 162.73141479492188\n",
      "118 153.76666259765625\n",
      "119 145.31301879882812\n",
      "120 137.3474884033203\n",
      "121 129.83546447753906\n",
      "122 122.7516098022461\n",
      "123 116.07182312011719\n",
      "124 109.76952362060547\n",
      "125 103.82550048828125\n",
      "126 98.21338653564453\n",
      "127 92.9182357788086\n",
      "128 87.91755676269531\n",
      "129 83.19667053222656\n",
      "130 78.74081420898438\n",
      "131 74.53215026855469\n",
      "132 70.55763244628906\n",
      "133 66.80384826660156\n",
      "134 63.26255798339844\n",
      "135 59.90830612182617\n",
      "136 56.739532470703125\n",
      "137 53.746028900146484\n",
      "138 50.91431427001953\n",
      "139 48.23752212524414\n",
      "140 45.706321716308594\n",
      "141 43.312374114990234\n",
      "142 41.0498046875\n",
      "143 38.9092903137207\n",
      "144 36.883609771728516\n",
      "145 34.96672439575195\n",
      "146 33.15319061279297\n",
      "147 31.43661880493164\n",
      "148 29.811723709106445\n",
      "149 28.274412155151367\n",
      "150 26.818384170532227\n",
      "151 25.439573287963867\n",
      "152 24.135595321655273\n",
      "153 22.899757385253906\n",
      "154 21.728557586669922\n",
      "155 20.61960220336914\n",
      "156 19.568519592285156\n",
      "157 18.572437286376953\n",
      "158 17.62940788269043\n",
      "159 16.7347354888916\n",
      "160 15.887794494628906\n",
      "161 15.084329605102539\n",
      "162 14.322635650634766\n",
      "163 13.601385116577148\n",
      "164 12.917522430419922\n",
      "165 12.26827335357666\n",
      "166 11.652848243713379\n",
      "167 11.069241523742676\n",
      "168 10.515504837036133\n",
      "169 9.990549087524414\n",
      "170 9.492585182189941\n",
      "171 9.020386695861816\n",
      "172 8.57190227508545\n",
      "173 8.14617919921875\n",
      "174 7.7421956062316895\n",
      "175 7.359133720397949\n",
      "176 6.995365619659424\n",
      "177 6.650121688842773\n",
      "178 6.322197437286377\n",
      "179 6.0107197761535645\n",
      "180 5.7151594161987305\n",
      "181 5.43440580368042\n",
      "182 5.168035984039307\n",
      "183 4.914912223815918\n",
      "184 4.674349784851074\n",
      "185 4.446157455444336\n",
      "186 4.229350566864014\n",
      "187 4.0233893394470215\n",
      "188 3.827320098876953\n",
      "189 3.641603946685791\n",
      "190 3.4649078845977783\n",
      "191 3.296902656555176\n",
      "192 3.13732647895813\n",
      "193 2.985650062561035\n",
      "194 2.84126615524292\n",
      "195 2.704190492630005\n",
      "196 2.573923110961914\n",
      "197 2.4497575759887695\n",
      "198 2.3320817947387695\n",
      "199 2.220238208770752\n",
      "200 2.113861322402954\n",
      "201 2.012514114379883\n",
      "202 1.9161680936813354\n",
      "203 1.8245352506637573\n",
      "204 1.737392783164978\n",
      "205 1.654557466506958\n",
      "206 1.575671672821045\n",
      "207 1.5006484985351562\n",
      "208 1.4293434619903564\n",
      "209 1.361525535583496\n",
      "210 1.2970008850097656\n",
      "211 1.2356047630310059\n",
      "212 1.1769708395004272\n",
      "213 1.121382474899292\n",
      "214 1.068307638168335\n",
      "215 1.017873764038086\n",
      "216 0.9698413610458374\n",
      "217 0.924199640750885\n",
      "218 0.880634069442749\n",
      "219 0.8391958475112915\n",
      "220 0.7998542189598083\n",
      "221 0.7623925805091858\n",
      "222 0.7265488505363464\n",
      "223 0.6925909519195557\n",
      "224 0.6601446270942688\n",
      "225 0.6292644739151001\n",
      "226 0.5999276638031006\n",
      "227 0.5719099044799805\n",
      "228 0.5452060103416443\n",
      "229 0.5197786688804626\n",
      "230 0.4956164062023163\n",
      "231 0.4726499915122986\n",
      "232 0.4506691098213196\n",
      "233 0.42974624037742615\n",
      "234 0.4098668396472931\n",
      "235 0.3908653259277344\n",
      "236 0.37274911999702454\n",
      "237 0.3555005192756653\n",
      "238 0.33910003304481506\n",
      "239 0.32336941361427307\n",
      "240 0.3085014820098877\n",
      "241 0.29431116580963135\n",
      "242 0.2807413339614868\n",
      "243 0.2677685022354126\n",
      "244 0.2554665505886078\n",
      "245 0.2436874657869339\n",
      "246 0.23253324627876282\n",
      "247 0.22185273468494415\n",
      "248 0.21171069145202637\n",
      "249 0.20198211073875427\n",
      "250 0.19276385009288788\n",
      "251 0.18399187922477722\n",
      "252 0.17562691867351532\n",
      "253 0.16758641600608826\n",
      "254 0.15990544855594635\n",
      "255 0.15264223515987396\n",
      "256 0.14564864337444305\n",
      "257 0.13902679085731506\n",
      "258 0.13273201882839203\n",
      "259 0.12666800618171692\n",
      "260 0.12093237787485123\n",
      "261 0.11543108522891998\n",
      "262 0.11021513491868973\n",
      "263 0.1052103117108345\n",
      "264 0.10043814778327942\n",
      "265 0.09588806331157684\n",
      "266 0.09154975414276123\n",
      "267 0.08739864826202393\n",
      "268 0.08345325291156769\n",
      "269 0.07972614467144012\n",
      "270 0.07613605260848999\n",
      "271 0.07268042117357254\n",
      "272 0.06940504163503647\n",
      "273 0.06628608703613281\n",
      "274 0.06329507380723953\n",
      "275 0.06047424301505089\n",
      "276 0.05775189772248268\n",
      "277 0.05516704544425011\n",
      "278 0.0526936836540699\n",
      "279 0.05033908784389496\n",
      "280 0.04808907210826874\n",
      "281 0.04593110457062721\n",
      "282 0.0438791885972023\n",
      "283 0.041909657418727875\n",
      "284 0.04003579169511795\n",
      "285 0.0382564477622509\n",
      "286 0.036551062017679214\n",
      "287 0.034930821508169174\n",
      "288 0.033384066075086594\n",
      "289 0.03190836310386658\n",
      "290 0.030493615195155144\n",
      "291 0.029123393818736076\n",
      "292 0.027827061712741852\n",
      "293 0.026617085561156273\n",
      "294 0.025423692539334297\n",
      "295 0.0242997445166111\n",
      "296 0.02322799526154995\n",
      "297 0.022215187549591064\n",
      "298 0.021235942840576172\n",
      "299 0.02030537836253643\n",
      "300 0.019420076161623\n",
      "301 0.018567845225334167\n",
      "302 0.017762761563062668\n",
      "303 0.016983527690172195\n",
      "304 0.016247643157839775\n",
      "305 0.015536973252892494\n",
      "306 0.014867900870740414\n",
      "307 0.014218415133655071\n",
      "308 0.013607827015221119\n",
      "309 0.013014137744903564\n",
      "310 0.012448066845536232\n",
      "311 0.011909053660929203\n",
      "312 0.011402872391045094\n",
      "313 0.010916064493358135\n",
      "314 0.010446585714817047\n",
      "315 0.00999621581286192\n",
      "316 0.00957691203802824\n",
      "317 0.009165480732917786\n",
      "318 0.00877241138368845\n",
      "319 0.008399822749197483\n",
      "320 0.008046436123549938\n",
      "321 0.00770566938444972\n",
      "322 0.007382671814411879\n",
      "323 0.007072163745760918\n",
      "324 0.00677498010918498\n",
      "325 0.006491651758551598\n",
      "326 0.0062223151326179504\n",
      "327 0.00596333434805274\n",
      "328 0.0057188053615391254\n",
      "329 0.005482795648276806\n",
      "330 0.005255064927041531\n",
      "331 0.0050399163737893105\n",
      "332 0.004831089172512293\n",
      "333 0.004632201511412859\n",
      "334 0.004448164254426956\n",
      "335 0.004265293013304472\n",
      "336 0.004094194155186415\n",
      "337 0.003930015955120325\n",
      "338 0.003771913005039096\n",
      "339 0.0036233803257346153\n",
      "340 0.003479854902252555\n",
      "341 0.0033415285870432854\n",
      "342 0.0032073436304926872\n",
      "343 0.003084970638155937\n",
      "344 0.002963237464427948\n",
      "345 0.0028503225184977055\n",
      "346 0.0027396189980208874\n",
      "347 0.00263512646779418\n",
      "348 0.0025320597924292088\n",
      "349 0.002435204340144992\n",
      "350 0.0023439025972038507\n",
      "351 0.002255948493257165\n",
      "352 0.002173986053094268\n",
      "353 0.002093964722007513\n",
      "354 0.0020143496803939342\n",
      "355 0.0019396069692447782\n",
      "356 0.0018702168017625809\n",
      "357 0.001800707308575511\n",
      "358 0.001735907280817628\n",
      "359 0.001674081664532423\n",
      "360 0.0016158513026311994\n",
      "361 0.0015578533057123423\n",
      "362 0.0015030726790428162\n",
      "363 0.0014500580728054047\n",
      "364 0.001399516244418919\n",
      "365 0.001348647871054709\n",
      "366 0.0013006930239498615\n",
      "367 0.0012558521702885628\n",
      "368 0.001213662326335907\n",
      "369 0.0011701963376253843\n",
      "370 0.001130865071900189\n",
      "371 0.0010936352191492915\n",
      "372 0.0010570053709670901\n",
      "373 0.0010221530683338642\n",
      "374 0.000990341417491436\n",
      "375 0.0009570842958055437\n",
      "376 0.0009265842963941395\n",
      "377 0.0008967797039076686\n",
      "378 0.0008672148105688393\n",
      "379 0.0008407296263612807\n",
      "380 0.00081435072934255\n",
      "381 0.0007869318360462785\n",
      "382 0.000764625146985054\n",
      "383 0.000739276350941509\n",
      "384 0.0007172245532274246\n",
      "385 0.000694687943905592\n",
      "386 0.0006735861534252763\n",
      "387 0.0006534277345053852\n",
      "388 0.0006342795677483082\n",
      "389 0.0006158404285088181\n",
      "390 0.0005972310318611562\n",
      "391 0.0005792733863927424\n",
      "392 0.0005629532970488071\n",
      "393 0.0005464825080707669\n",
      "394 0.0005309455445967615\n",
      "395 0.000515883497428149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396 0.0005013043992221355\n",
      "397 0.00048699017497710884\n",
      "398 0.000472259329399094\n",
      "399 0.00045960803981870413\n",
      "400 0.0004471045976970345\n",
      "401 0.00043520593317225575\n",
      "402 0.00042335345642641187\n",
      "403 0.0004112966125831008\n",
      "404 0.00040016122511588037\n",
      "405 0.00038875493919476867\n",
      "406 0.00037827156484127045\n",
      "407 0.00036886133602820337\n",
      "408 0.0003590162086766213\n",
      "409 0.000349351204931736\n",
      "410 0.0003400190907996148\n",
      "411 0.00033140479354187846\n",
      "412 0.00032377056777477264\n",
      "413 0.0003151167184114456\n",
      "414 0.0003078094741795212\n",
      "415 0.00029987021116539836\n",
      "416 0.00029239553259685636\n",
      "417 0.0002848532749339938\n",
      "418 0.000278331310255453\n",
      "419 0.0002719059120863676\n",
      "420 0.0002641771570779383\n",
      "421 0.0002582455053925514\n",
      "422 0.0002521526475902647\n",
      "423 0.0002469007740728557\n",
      "424 0.00024147699878085405\n",
      "425 0.00023602857254445553\n",
      "426 0.00023036942002363503\n",
      "427 0.0002254108985653147\n",
      "428 0.0002194691332988441\n",
      "429 0.00021511735394597054\n",
      "430 0.00021064399334136397\n",
      "431 0.00020559744734782726\n",
      "432 0.0002014078781940043\n",
      "433 0.0001966930867638439\n",
      "434 0.00019291977514512837\n",
      "435 0.00018823982100002468\n",
      "436 0.00018437299877405167\n",
      "437 0.0001811552356230095\n",
      "438 0.00017718056915327907\n",
      "439 0.00017360187484882772\n",
      "440 0.00017013437172863632\n",
      "441 0.00016610177408438176\n",
      "442 0.00016219046665355563\n",
      "443 0.0001592715416336432\n",
      "444 0.0001557614596094936\n",
      "445 0.00015267047274392098\n",
      "446 0.0001500551006756723\n",
      "447 0.00014656306302640587\n",
      "448 0.0001439624174963683\n",
      "449 0.0001410732074873522\n",
      "450 0.0001379111927235499\n",
      "451 0.0001353243860648945\n",
      "452 0.00013303283776622266\n",
      "453 0.00013063588994555175\n",
      "454 0.000127855921164155\n",
      "455 0.000125349557492882\n",
      "456 0.00012326006253715605\n",
      "457 0.00012094974226783961\n",
      "458 0.00011859257938340306\n",
      "459 0.00011649740190478042\n",
      "460 0.00011400844960007817\n",
      "461 0.00011213372636120766\n",
      "462 0.00011011341121047735\n",
      "463 0.00010845976794371381\n",
      "464 0.00010673783981474116\n",
      "465 0.00010489395208423957\n",
      "466 0.00010295658285031095\n",
      "467 0.000101227626146283\n",
      "468 9.936626884154975e-05\n",
      "469 9.768385643837973e-05\n",
      "470 9.565173968439922e-05\n",
      "471 9.401825082022697e-05\n",
      "472 9.250826406059787e-05\n",
      "473 9.113330452237278e-05\n",
      "474 8.965030428953469e-05\n",
      "475 8.822233940009028e-05\n",
      "476 8.647632785141468e-05\n",
      "477 8.533741493010893e-05\n",
      "478 8.35772225400433e-05\n",
      "479 8.236307621700689e-05\n",
      "480 8.122593135340139e-05\n",
      "481 7.994754560058936e-05\n",
      "482 7.869608816690743e-05\n",
      "483 7.739829015918076e-05\n",
      "484 7.605984137626365e-05\n",
      "485 7.496316538890824e-05\n",
      "486 7.396255386993289e-05\n",
      "487 7.27086080587469e-05\n",
      "488 7.153816113714129e-05\n",
      "489 7.02597462804988e-05\n",
      "490 6.925148045411333e-05\n",
      "491 6.85486666043289e-05\n",
      "492 6.77085918141529e-05\n",
      "493 6.67946005705744e-05\n",
      "494 6.60133664496243e-05\n",
      "495 6.486153142759576e-05\n",
      "496 6.383428262779489e-05\n",
      "497 6.298712833086029e-05\n",
      "498 6.230182771105319e-05\n",
      "499 6.147141539258882e-05\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    # An alternative way is to operate on weight.data and weight.grad.data.\n",
    "    # Recall that tensor.data gives a tensor that shares the storage with\n",
    "    # tensor, but doesn't track history.\n",
    "    # You can also use torch.optim.SGD to achieve this.\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    #optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 658.7985229492188\n",
      "1 654.87548828125\n",
      "2 651.9625854492188\n",
      "3 652.5747680664062\n",
      "4 650.5530395507812\n",
      "5 699.179931640625\n",
      "6 645.9085693359375\n",
      "7 596.5341796875\n",
      "8 603.4854736328125\n",
      "9 640.6136474609375\n",
      "10 589.0440673828125\n",
      "11 638.3933715820312\n",
      "12 627.1065063476562\n",
      "13 624.5576782226562\n",
      "14 553.2034301757812\n",
      "15 634.4506225585938\n",
      "16 632.9016723632812\n",
      "17 630.8174438476562\n",
      "18 602.0353393554688\n",
      "19 594.7101440429688\n",
      "20 284.49945068359375\n",
      "21 470.2591857910156\n",
      "22 448.33001708984375\n",
      "23 547.2080688476562\n",
      "24 198.239501953125\n",
      "25 509.330810546875\n",
      "26 568.8136596679688\n",
      "27 316.98529052734375\n",
      "28 428.1928405761719\n",
      "29 494.2279052734375\n",
      "30 359.2505798339844\n",
      "31 326.2535095214844\n",
      "32 295.0746765136719\n",
      "33 265.4187316894531\n",
      "34 307.094482421875\n",
      "35 236.27230834960938\n",
      "36 207.75161743164062\n",
      "37 250.3546142578125\n",
      "38 263.0369567871094\n",
      "39 246.3397979736328\n",
      "40 92.18124389648438\n",
      "41 204.2117919921875\n",
      "42 152.2781524658203\n",
      "43 144.4793701171875\n",
      "44 125.41231536865234\n",
      "45 101.7720947265625\n",
      "46 129.4358367919922\n",
      "47 239.03396606445312\n",
      "48 93.8172378540039\n",
      "49 234.76268005371094\n",
      "50 80.65991973876953\n",
      "51 102.25804901123047\n",
      "52 60.602516174316406\n",
      "53 53.006526947021484\n",
      "54 168.04803466796875\n",
      "55 80.15363311767578\n",
      "56 164.6822509765625\n",
      "57 71.8517074584961\n",
      "58 128.8114776611328\n",
      "59 91.90506744384766\n",
      "60 60.53025817871094\n",
      "61 76.62509155273438\n",
      "62 61.38839340209961\n",
      "63 40.74219512939453\n",
      "64 57.91259002685547\n",
      "65 50.24884796142578\n",
      "66 41.55618667602539\n",
      "67 89.70661163330078\n",
      "68 76.31180572509766\n",
      "69 57.411521911621094\n",
      "70 25.384807586669922\n",
      "71 78.22804260253906\n",
      "72 54.080875396728516\n",
      "73 25.751283645629883\n",
      "74 47.43484115600586\n",
      "75 60.10255813598633\n",
      "76 35.83717727661133\n",
      "77 23.07640838623047\n",
      "78 31.15259552001953\n",
      "79 37.42622375488281\n",
      "80 24.825260162353516\n",
      "81 41.655555725097656\n",
      "82 32.10667419433594\n",
      "83 23.656604766845703\n",
      "84 32.977149963378906\n",
      "85 38.96644973754883\n",
      "86 18.98097801208496\n",
      "87 9.429216384887695\n",
      "88 26.73440933227539\n",
      "89 17.279096603393555\n",
      "90 31.38123321533203\n",
      "91 29.75938606262207\n",
      "92 18.380596160888672\n",
      "93 31.3973331451416\n",
      "94 16.019493103027344\n",
      "95 23.17518424987793\n",
      "96 15.17919635772705\n",
      "97 11.1022367477417\n",
      "98 9.527140617370605\n",
      "99 20.175199508666992\n",
      "100 36.680946350097656\n",
      "101 7.508305549621582\n",
      "102 13.759544372558594\n",
      "103 19.529146194458008\n",
      "104 26.66462516784668\n",
      "105 7.900022506713867\n",
      "106 7.2658586502075195\n",
      "107 10.746084213256836\n",
      "108 17.990535736083984\n",
      "109 7.749882221221924\n",
      "110 7.3166823387146\n",
      "111 4.836940765380859\n",
      "112 14.388608932495117\n",
      "113 11.553436279296875\n",
      "114 15.643580436706543\n",
      "115 11.232836723327637\n",
      "116 6.456793785095215\n",
      "117 3.5984368324279785\n",
      "118 29.039234161376953\n",
      "119 7.472711563110352\n",
      "120 3.5521953105926514\n",
      "121 9.514700889587402\n",
      "122 7.793854713439941\n",
      "123 6.428175926208496\n",
      "124 8.284706115722656\n",
      "125 5.819406032562256\n",
      "126 3.560399055480957\n",
      "127 14.040688514709473\n",
      "128 13.153895378112793\n",
      "129 9.163270950317383\n",
      "130 7.67692756652832\n",
      "131 4.143229961395264\n",
      "132 2.869581460952759\n",
      "133 8.802383422851562\n",
      "134 9.435508728027344\n",
      "135 5.960194110870361\n",
      "136 3.3392133712768555\n",
      "137 11.032731056213379\n",
      "138 3.8388967514038086\n",
      "139 5.392164707183838\n",
      "140 4.347467422485352\n",
      "141 3.3316428661346436\n",
      "142 2.618835210800171\n",
      "143 1.9664205312728882\n",
      "144 2.2374942302703857\n",
      "145 23.802900314331055\n",
      "146 2.545180320739746\n",
      "147 5.175321578979492\n",
      "148 3.085150957107544\n",
      "149 7.6651201248168945\n",
      "150 19.348648071289062\n",
      "151 2.7631804943084717\n",
      "152 6.300424575805664\n",
      "153 9.391295433044434\n",
      "154 6.416811466217041\n",
      "155 3.41961407661438\n",
      "156 3.1192939281463623\n",
      "157 13.122254371643066\n",
      "158 2.0352487564086914\n",
      "159 1.7160216569900513\n",
      "160 2.32574200630188\n",
      "161 7.107022285461426\n",
      "162 5.358274459838867\n",
      "163 10.616851806640625\n",
      "164 3.293961524963379\n",
      "165 3.5829660892486572\n",
      "166 4.564126491546631\n",
      "167 1.9429889917373657\n",
      "168 3.526155710220337\n",
      "169 3.049238681793213\n",
      "170 2.1270320415496826\n",
      "171 2.6283762454986572\n",
      "172 2.127068281173706\n",
      "173 1.0308892726898193\n",
      "174 1.269981026649475\n",
      "175 1.926457405090332\n",
      "176 14.21249771118164\n",
      "177 1.5474315881729126\n",
      "178 1.6051913499832153\n",
      "179 1.9026453495025635\n",
      "180 25.9307918548584\n",
      "181 0.5419245958328247\n",
      "182 2.3887646198272705\n",
      "183 24.224401473999023\n",
      "184 2.6316874027252197\n",
      "185 1.6510870456695557\n",
      "186 19.123226165771484\n",
      "187 0.554765522480011\n",
      "188 4.1980977058410645\n",
      "189 9.660807609558105\n",
      "190 0.6513808369636536\n",
      "191 0.5506529211997986\n",
      "192 6.965535640716553\n",
      "193 10.71432113647461\n",
      "194 2.3042702674865723\n",
      "195 7.188431739807129\n",
      "196 7.321136951446533\n",
      "197 1.6076358556747437\n",
      "198 1.6828715801239014\n",
      "199 0.488262414932251\n",
      "200 4.731064796447754\n",
      "201 4.896605014801025\n",
      "202 0.528052031993866\n",
      "203 1.6846835613250732\n",
      "204 6.482969284057617\n",
      "205 6.738275051116943\n",
      "206 12.8290433883667\n",
      "207 12.232390403747559\n",
      "208 6.495199203491211\n",
      "209 3.043642997741699\n",
      "210 4.051413059234619\n",
      "211 21.842628479003906\n",
      "212 1.641464114189148\n",
      "213 2.333831548690796\n",
      "214 3.148193597793579\n",
      "215 0.8654630184173584\n",
      "216 3.358977794647217\n",
      "217 1.137811303138733\n",
      "218 1.9262850284576416\n",
      "219 2.697784185409546\n",
      "220 1.3115184307098389\n",
      "221 1.0967786312103271\n",
      "222 3.2590208053588867\n",
      "223 1.7449249029159546\n",
      "224 1.0241363048553467\n",
      "225 0.8951457738876343\n",
      "226 1.8580108880996704\n",
      "227 1.4093998670578003\n",
      "228 3.642601490020752\n",
      "229 0.7894397377967834\n",
      "230 1.053001880645752\n",
      "231 1.1802526712417603\n",
      "232 1.023032784461975\n",
      "233 0.5584573149681091\n",
      "234 1.1222383975982666\n",
      "235 0.7535632252693176\n",
      "236 0.8095365166664124\n",
      "237 0.638214647769928\n",
      "238 0.9375042915344238\n",
      "239 2.6500415802001953\n",
      "240 1.5594767332077026\n",
      "241 1.1783889532089233\n",
      "242 0.9572879672050476\n",
      "243 0.9747079610824585\n",
      "244 4.562020778656006\n",
      "245 0.5973771214485168\n",
      "246 0.656184196472168\n",
      "247 1.7302193641662598\n",
      "248 3.8503386974334717\n",
      "249 0.9336763620376587\n",
      "250 1.1316959857940674\n",
      "251 1.878286361694336\n",
      "252 1.4658474922180176\n",
      "253 0.47103267908096313\n",
      "254 1.798071026802063\n",
      "255 0.44151946902275085\n",
      "256 0.9709099531173706\n",
      "257 1.7361364364624023\n",
      "258 0.3523555397987366\n",
      "259 0.7772191166877747\n",
      "260 1.2368617057800293\n",
      "261 0.17669212818145752\n",
      "262 0.1605796217918396\n",
      "263 0.6811233758926392\n",
      "264 1.0011225938796997\n",
      "265 0.5980188846588135\n",
      "266 0.48450180888175964\n",
      "267 0.38925737142562866\n",
      "268 0.8384832739830017\n",
      "269 1.192260503768921\n",
      "270 0.1803036481142044\n",
      "271 2.3747265338897705\n",
      "272 2.075237989425659\n",
      "273 0.5757654309272766\n",
      "274 0.6699948310852051\n",
      "275 1.8583528995513916\n",
      "276 1.3230407238006592\n",
      "277 0.8672323226928711\n",
      "278 1.9460915327072144\n",
      "279 1.0424028635025024\n",
      "280 0.6966226696968079\n",
      "281 1.2917709350585938\n",
      "282 0.8452527523040771\n",
      "283 1.976167917251587\n",
      "284 0.846279501914978\n",
      "285 1.7991642951965332\n",
      "286 0.5562490820884705\n",
      "287 1.1847798824310303\n",
      "288 0.23937632143497467\n",
      "289 0.8052167296409607\n",
      "290 1.79354727268219\n",
      "291 1.4449939727783203\n",
      "292 0.6815866827964783\n",
      "293 0.6937975883483887\n",
      "294 1.0389678478240967\n",
      "295 1.0979214906692505\n",
      "296 0.8022865056991577\n",
      "297 0.2006513923406601\n",
      "298 0.6366604566574097\n",
      "299 0.33931854367256165\n",
      "300 0.32244765758514404\n",
      "301 7.742103099822998\n",
      "302 0.7015981078147888\n",
      "303 3.3863697052001953\n",
      "304 2.828677177429199\n",
      "305 4.762943267822266\n",
      "306 0.9491289258003235\n",
      "307 4.57847785949707\n",
      "308 3.4753835201263428\n",
      "309 0.40646424889564514\n",
      "310 0.5191571116447449\n",
      "311 1.182478904724121\n",
      "312 8.96149730682373\n",
      "313 11.278519630432129\n",
      "314 3.3041181564331055\n",
      "315 13.934645652770996\n",
      "316 12.08831787109375\n",
      "317 5.076000690460205\n",
      "318 0.7447565793991089\n",
      "319 11.69222640991211\n",
      "320 6.366405487060547\n",
      "321 2.1482720375061035\n",
      "322 1.098118782043457\n",
      "323 0.8877279758453369\n",
      "324 2.314833879470825\n",
      "325 0.4899909496307373\n",
      "326 19.337970733642578\n",
      "327 26.293601989746094\n",
      "328 8.122175216674805\n",
      "329 22.927824020385742\n",
      "330 37.909183502197266\n",
      "331 11.22480583190918\n",
      "332 1.6822829246520996\n",
      "333 4.174575328826904\n",
      "334 9.298477172851562\n",
      "335 19.3499813079834\n",
      "336 10.869314193725586\n",
      "337 7.103465557098389\n",
      "338 7.607293128967285\n",
      "339 2.7582180500030518\n",
      "340 1.0299620628356934\n",
      "341 1.5481550693511963\n",
      "342 5.097469806671143\n",
      "343 4.922546863555908\n",
      "344 21.73405647277832\n",
      "345 3.976057767868042\n",
      "346 1.541831135749817\n",
      "347 14.153520584106445\n",
      "348 12.550577163696289\n",
      "349 0.8106052279472351\n",
      "350 2.312804937362671\n",
      "351 6.7547287940979\n",
      "352 5.69002103805542\n",
      "353 6.860036849975586\n",
      "354 1.9668587446212769\n",
      "355 3.942514419555664\n",
      "356 1.8685059547424316\n",
      "357 6.946406364440918\n",
      "358 4.349694728851318\n",
      "359 1.863568663597107\n",
      "360 2.1510376930236816\n",
      "361 1.085193157196045\n",
      "362 0.9641583561897278\n",
      "363 1.7838870286941528\n",
      "364 2.4265167713165283\n",
      "365 2.1256072521209717\n",
      "366 0.5948395729064941\n",
      "367 0.7055073380470276\n",
      "368 1.1909959316253662\n",
      "369 1.4787858724594116\n",
      "370 0.9638614058494568\n",
      "371 1.3553657531738281\n",
      "372 2.6543467044830322\n",
      "373 1.6969590187072754\n",
      "374 3.484922409057617\n",
      "375 3.0893194675445557\n",
      "376 1.5906671285629272\n",
      "377 1.049883484840393\n",
      "378 2.2309930324554443\n",
      "379 0.8912315368652344\n",
      "380 1.0731816291809082\n",
      "381 0.8487759828567505\n",
      "382 1.8820260763168335\n",
      "383 0.277182012796402\n",
      "384 0.9207116365432739\n",
      "385 0.375137060880661\n",
      "386 0.35339152812957764\n",
      "387 0.26580461859703064\n",
      "388 0.19291165471076965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389 0.17942774295806885\n",
      "390 0.785534143447876\n",
      "391 1.4661474227905273\n",
      "392 0.5995476841926575\n",
      "393 0.20321378111839294\n",
      "394 0.18399570882320404\n",
      "395 0.16826759278774261\n",
      "396 0.5119891166687012\n",
      "397 0.4378575384616852\n",
      "398 0.33476343750953674\n",
      "399 0.2180519998073578\n",
      "400 0.3213740289211273\n",
      "401 0.27723294496536255\n",
      "402 0.21260696649551392\n",
      "403 0.27224284410476685\n",
      "404 0.2927769720554352\n",
      "405 0.45235589146614075\n",
      "406 0.2761409282684326\n",
      "407 0.18918414413928986\n",
      "408 0.3462660014629364\n",
      "409 0.18316973745822906\n",
      "410 0.35173335671424866\n",
      "411 0.1747814565896988\n",
      "412 0.13188958168029785\n",
      "413 0.13506630063056946\n",
      "414 0.19955064356327057\n",
      "415 0.18865376710891724\n",
      "416 1.8408479690551758\n",
      "417 1.4305853843688965\n",
      "418 1.320589542388916\n",
      "419 1.2433329820632935\n",
      "420 0.42504656314849854\n",
      "421 0.6870096325874329\n",
      "422 0.9327274560928345\n",
      "423 0.27909931540489197\n",
      "424 0.6972293257713318\n",
      "425 0.5941821336746216\n",
      "426 0.271371066570282\n",
      "427 0.4581674039363861\n",
      "428 0.5121147632598877\n",
      "429 0.6815093755722046\n",
      "430 0.3699913024902344\n",
      "431 0.5696294903755188\n",
      "432 0.7619664669036865\n",
      "433 0.6867704391479492\n",
      "434 0.7130403518676758\n",
      "435 0.2676972448825836\n",
      "436 0.25242137908935547\n",
      "437 0.5747681856155396\n",
      "438 0.19174399971961975\n",
      "439 0.518720805644989\n",
      "440 0.32415562868118286\n",
      "441 0.3196347653865814\n",
      "442 0.13141658902168274\n",
      "443 0.12392979860305786\n",
      "444 0.45066291093826294\n",
      "445 0.3968185782432556\n",
      "446 0.373979389667511\n",
      "447 0.36469602584838867\n",
      "448 0.6746253371238708\n",
      "449 0.12966710329055786\n",
      "450 0.4020240902900696\n",
      "451 0.38924500346183777\n",
      "452 0.10033399611711502\n",
      "453 0.6288227438926697\n",
      "454 0.09044080227613449\n",
      "455 0.3891851007938385\n",
      "456 0.32263681292533875\n",
      "457 0.49824070930480957\n",
      "458 0.4928189516067505\n",
      "459 0.45239830017089844\n",
      "460 0.3598542809486389\n",
      "461 0.0937056839466095\n",
      "462 0.09911530464887619\n",
      "463 0.7721636295318604\n",
      "464 0.37192127108573914\n",
      "465 0.5241280794143677\n",
      "466 0.8876041173934937\n",
      "467 0.4355141520500183\n",
      "468 0.4158087372779846\n",
      "469 0.7724641561508179\n",
      "470 0.40782737731933594\n",
      "471 0.3591097593307495\n",
      "472 0.12266762554645538\n",
      "473 0.4774533808231354\n",
      "474 0.15795299410820007\n",
      "475 0.46319276094436646\n",
      "476 0.7672303915023804\n",
      "477 0.5530645251274109\n",
      "478 0.8863035440444946\n",
      "479 0.9210216999053955\n",
      "480 0.5168441534042358\n",
      "481 0.134703129529953\n",
      "482 0.4192700982093811\n",
      "483 1.080348253250122\n",
      "484 0.1261831820011139\n",
      "485 1.3382127285003662\n",
      "486 0.6792954802513123\n",
      "487 0.36992648243904114\n",
      "488 2.5737996101379395\n",
      "489 0.7689510583877563\n",
      "490 0.9489753842353821\n",
      "491 0.4470428228378296\n",
      "492 0.5321885347366333\n",
      "493 0.12217327952384949\n",
      "494 2.545891284942627\n",
      "495 0.4797004759311676\n",
      "496 1.3593322038650513\n",
      "497 1.7242664098739624\n",
      "498 0.636887788772583\n",
      "499 0.6761477589607239\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('input_linear.weight', Parameter containing:\n",
       "  tensor([[-0.0125, -0.0227, -0.0143,  ...,  0.0092, -0.0204,  0.0069],\n",
       "          [-0.0307,  0.0067, -0.0283,  ..., -0.0128,  0.0063, -0.0012],\n",
       "          [ 0.0343,  0.0150, -0.0090,  ..., -0.0149, -0.0342,  0.0276],\n",
       "          ...,\n",
       "          [ 0.0265,  0.0033,  0.0405,  ...,  0.0130,  0.0005,  0.0003],\n",
       "          [-0.0046, -0.0193, -0.0104,  ...,  0.0070, -0.0235, -0.0180],\n",
       "          [ 0.0223,  0.0050,  0.0194,  ...,  0.0280,  0.0031,  0.0013]],\n",
       "         requires_grad=True)), ('input_linear.bias', Parameter containing:\n",
       "  tensor([-0.0157, -0.0241,  0.0133,  0.0260, -0.0204, -0.0091, -0.0268, -0.0352,\n",
       "          -0.0032,  0.0019,  0.0213,  0.0101,  0.0306, -0.0148, -0.0394, -0.0184,\n",
       "          -0.0396,  0.0113, -0.0358, -0.0210, -0.0276,  0.0173,  0.0182, -0.0173,\n",
       "          -0.0056, -0.0255,  0.0114,  0.0161,  0.0019, -0.0322, -0.0153,  0.0058,\n",
       "           0.0019,  0.0182, -0.0124,  0.0025,  0.0041, -0.0167, -0.0139, -0.0068,\n",
       "           0.0114, -0.0286,  0.0192, -0.0161,  0.0167, -0.0216,  0.0122, -0.0158,\n",
       "           0.0090,  0.0291, -0.0131,  0.0124, -0.0113, -0.0108, -0.0347,  0.0049,\n",
       "          -0.0241, -0.0372, -0.0096,  0.0105,  0.0104,  0.0140, -0.0054,  0.0092,\n",
       "           0.0072, -0.0050,  0.0217, -0.0023,  0.0143,  0.0028, -0.0113,  0.0245,\n",
       "           0.0092,  0.0245, -0.0224, -0.0398,  0.0024, -0.0221, -0.0183, -0.0259,\n",
       "           0.0056, -0.0314,  0.0166,  0.0078,  0.0246, -0.0113,  0.0112, -0.0119,\n",
       "          -0.0086,  0.0086, -0.0111,  0.0097, -0.0112,  0.0188, -0.0047, -0.0235,\n",
       "          -0.0024,  0.0086, -0.0375, -0.0019], requires_grad=True)), ('middle_linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.3128, -0.0214, -0.0423,  ..., -0.0124,  0.0193,  0.0534],\n",
       "          [-0.0517, -0.0337, -0.0364,  ...,  0.0548, -0.0109,  0.0622],\n",
       "          [-0.0218, -0.0003,  0.3068,  ..., -0.0301,  0.0513, -0.0074],\n",
       "          ...,\n",
       "          [ 0.0059, -0.0762,  0.0161,  ...,  0.0436, -0.0259, -0.0657],\n",
       "          [ 0.1460,  0.0326,  0.1184,  ..., -0.0177,  0.1844,  0.0588],\n",
       "          [-0.0317, -0.0638,  0.0352,  ...,  0.0124, -0.0054,  0.0070]],\n",
       "         requires_grad=True)), ('middle_linear.bias', Parameter containing:\n",
       "  tensor([ 0.1000,  0.0618,  0.1811, -0.0176,  0.0347,  0.0130,  0.0383,  0.1082,\n",
       "          -0.0652,  0.0788, -0.0221,  0.0414, -0.0614, -0.0274,  0.0227,  0.0616,\n",
       "           0.1542,  0.0397,  0.0410,  0.0381, -0.0976,  0.0297, -0.0918,  0.0248,\n",
       "          -0.0482, -0.0141, -0.0141,  0.0948,  0.0784,  0.0463,  0.0008, -0.0017,\n",
       "          -0.0693, -0.0185,  0.1268,  0.0499,  0.1030,  0.1150,  0.0171, -0.0400,\n",
       "           0.0231, -0.0299, -0.0355,  0.0040,  0.0499,  0.0737, -0.0201,  0.0938,\n",
       "           0.0897,  0.0594,  0.1007, -0.0429, -0.0174, -0.0038,  0.1578,  0.1100,\n",
       "           0.0207, -0.0469,  0.0575,  0.0835,  0.0429, -0.0691,  0.0816, -0.0356,\n",
       "          -0.0660,  0.0566,  0.0275,  0.0044,  0.0500, -0.0477,  0.0112,  0.0873,\n",
       "           0.1368,  0.0919,  0.0910,  0.1151,  0.1407,  0.0374,  0.0442, -0.0617,\n",
       "           0.0854,  0.0232,  0.0439, -0.0061,  0.0060,  0.1401,  0.0165, -0.0914,\n",
       "           0.0759, -0.0741,  0.0007,  0.0975,  0.1565, -0.0183,  0.0239,  0.0154,\n",
       "          -0.0397, -0.0412, -0.0377, -0.0489], requires_grad=True)), ('output_linear.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0872, -0.0500, -0.0048,  0.0890, -0.1484, -0.1064, -0.0127, -0.0437,\n",
       "           -0.0504, -0.0392, -0.0019,  0.0828, -0.0884, -0.0345,  0.0625, -0.1653,\n",
       "           -0.0089, -0.0286, -0.0171, -0.0694,  0.0565, -0.0026,  0.0145,  0.0300,\n",
       "            0.0443, -0.2079,  0.1108, -0.0296, -0.1918,  0.0715,  0.1205,  0.0689,\n",
       "           -0.0214,  0.0956,  0.0911,  0.1459,  0.0809,  0.2181,  0.2421,  0.0901,\n",
       "            0.0361, -0.0535, -0.1459, -0.0230, -0.0202, -0.0333, -0.0429, -0.1016,\n",
       "           -0.1202, -0.0605, -0.0116, -0.1977,  0.0172,  0.0737, -0.0651,  0.0107,\n",
       "           -0.0068, -0.0989, -0.0565, -0.1020,  0.0852, -0.0330, -0.0316,  0.0863,\n",
       "           -0.0566, -0.1181,  0.1736,  0.0580,  0.0523,  0.0103,  0.0945, -0.1271,\n",
       "            0.1303,  0.0380,  0.0534,  0.1517, -0.0599, -0.0292,  0.0720,  0.0820,\n",
       "            0.0528, -0.0554,  0.0496,  0.0043, -0.1052, -0.1379,  0.0213, -0.0940,\n",
       "            0.0304, -0.2051,  0.0748, -0.0164,  0.0124, -0.1392,  0.1075, -0.0137,\n",
       "           -0.0508,  0.1405, -0.0077, -0.0662],\n",
       "          [ 0.1141,  0.0319,  0.0054, -0.0625, -0.0002, -0.0115,  0.1549,  0.0182,\n",
       "            0.0021,  0.0079, -0.0193,  0.0102,  0.0066,  0.1152,  0.0263, -0.0168,\n",
       "            0.0037,  0.1000, -0.0236,  0.0205,  0.0061, -0.1239, -0.0957, -0.1287,\n",
       "           -0.0422, -0.0771,  0.0928, -0.0095, -0.0962,  0.0778,  0.0825,  0.0368,\n",
       "           -0.0803, -0.0682, -0.1246,  0.1152,  0.1297, -0.1233, -0.0147,  0.0784,\n",
       "           -0.0225, -0.0103,  0.1204,  0.0559,  0.0097,  0.0523,  0.0239, -0.1594,\n",
       "           -0.0524, -0.1425,  0.0782,  0.0748, -0.0849, -0.0377, -0.0527,  0.1687,\n",
       "           -0.1324, -0.1043,  0.0355,  0.0773,  0.0248, -0.1172,  0.1992, -0.0290,\n",
       "           -0.0618,  0.0658,  0.1337,  0.0655, -0.1996,  0.0699,  0.0411,  0.0755,\n",
       "           -0.1021,  0.0894, -0.1192,  0.0160,  0.1944, -0.1267,  0.0063, -0.0641,\n",
       "            0.0754, -0.0851,  0.0786,  0.1124,  0.0779,  0.0458,  0.0378,  0.0511,\n",
       "           -0.0481,  0.1652, -0.0657,  0.0424, -0.2424, -0.1217, -0.0423,  0.0249,\n",
       "           -0.0833, -0.0213, -0.0580, -0.0647],\n",
       "          [-0.0127,  0.0038,  0.0892, -0.0454, -0.1733,  0.0413, -0.0205,  0.0854,\n",
       "            0.0096,  0.0230, -0.1001,  0.0829,  0.0320, -0.0426, -0.1352,  0.0855,\n",
       "           -0.1809, -0.0819,  0.0341, -0.0592,  0.0878,  0.0593, -0.1118, -0.1043,\n",
       "            0.0092,  0.0858,  0.0349,  0.1439, -0.0071,  0.0277, -0.0551,  0.0233,\n",
       "           -0.0363, -0.0040, -0.0382, -0.0275,  0.0597,  0.0275, -0.0624,  0.0339,\n",
       "           -0.0648, -0.0547, -0.0287,  0.0648,  0.1296, -0.0406,  0.2248,  0.0634,\n",
       "           -0.0678, -0.0968,  0.0133, -0.0496,  0.0512,  0.1438, -0.0272, -0.0249,\n",
       "            0.0204,  0.1701, -0.0979,  0.0640,  0.1212, -0.0288, -0.0705,  0.0724,\n",
       "            0.0003,  0.0327, -0.0174,  0.0335,  0.1377,  0.1112, -0.0397,  0.0692,\n",
       "            0.1124,  0.0096,  0.0088, -0.0059, -0.0386,  0.0629,  0.0691, -0.0417,\n",
       "           -0.0948, -0.0877, -0.0522, -0.0736,  0.1053, -0.1407,  0.0267,  0.1837,\n",
       "           -0.0510,  0.0298, -0.0331,  0.0584, -0.1016,  0.2437, -0.1593, -0.0491,\n",
       "           -0.0345, -0.0209, -0.1337,  0.1063],\n",
       "          [ 0.1723, -0.0688,  0.0984,  0.0314,  0.0516,  0.1570,  0.1256,  0.2260,\n",
       "           -0.1093,  0.0381,  0.0368,  0.0165, -0.0638, -0.0997,  0.0854,  0.0574,\n",
       "           -0.1991,  0.0982,  0.0940,  0.0498,  0.0014, -0.0619,  0.0111,  0.0834,\n",
       "           -0.0438,  0.0474, -0.1994, -0.0899,  0.0203, -0.0566,  0.0966,  0.1115,\n",
       "           -0.1304,  0.0243, -0.2020, -0.1001,  0.0539,  0.0756,  0.0456, -0.0286,\n",
       "           -0.1196, -0.0339, -0.0575,  0.1173,  0.0537, -0.0235, -0.2228,  0.1595,\n",
       "           -0.0317, -0.0256, -0.1987, -0.0907, -0.0731, -0.0232, -0.0065,  0.1030,\n",
       "           -0.0266,  0.0151, -0.1294,  0.0741, -0.1183, -0.0491, -0.0007,  0.1002,\n",
       "           -0.0565, -0.0283,  0.1344, -0.0823, -0.2010, -0.1142, -0.1493, -0.1129,\n",
       "           -0.0381,  0.1121, -0.0379,  0.0739, -0.1123, -0.0880, -0.1259,  0.0471,\n",
       "            0.0295,  0.0322, -0.0134, -0.1328, -0.0750, -0.0701,  0.0439,  0.0953,\n",
       "            0.0961,  0.0051,  0.1208, -0.0922,  0.0243,  0.0769, -0.0026,  0.1161,\n",
       "            0.1023,  0.1178,  0.1294,  0.1347],\n",
       "          [ 0.0679,  0.0007, -0.1674, -0.0891,  0.1056, -0.0364, -0.0552, -0.0505,\n",
       "            0.0228, -0.1254,  0.1394,  0.0865,  0.0518, -0.0614,  0.0496, -0.0226,\n",
       "            0.1346,  0.1221,  0.1013, -0.1738, -0.0446, -0.0732,  0.0120,  0.1958,\n",
       "           -0.0207, -0.0191,  0.0616, -0.1011, -0.0043, -0.1185,  0.2109, -0.0881,\n",
       "           -0.0689, -0.0435, -0.0148, -0.0183, -0.0885, -0.2127, -0.0795,  0.0248,\n",
       "            0.1664, -0.0291,  0.1214,  0.0074, -0.0114, -0.0172,  0.0809, -0.0185,\n",
       "           -0.0230,  0.1060, -0.1663, -0.0160, -0.0813, -0.0171,  0.0426,  0.0354,\n",
       "           -0.1553,  0.0804, -0.0751,  0.0718,  0.1119,  0.0462,  0.1404, -0.1615,\n",
       "            0.0944,  0.2134, -0.1401,  0.0608, -0.0585, -0.0327, -0.0547, -0.0135,\n",
       "            0.1790, -0.0579,  0.0048,  0.0876,  0.0442, -0.0660, -0.0335, -0.0407,\n",
       "            0.1872,  0.0057, -0.0725, -0.0156, -0.0081,  0.0021,  0.0484,  0.1462,\n",
       "            0.0507, -0.0742,  0.0277, -0.1088,  0.0124,  0.0502, -0.0397,  0.0404,\n",
       "           -0.0391,  0.0248, -0.0119,  0.0313],\n",
       "          [ 0.1313, -0.0215,  0.2396,  0.0847,  0.1366, -0.0427,  0.0758,  0.0861,\n",
       "           -0.0400, -0.0644,  0.0301, -0.0456, -0.0563,  0.0651,  0.1402, -0.0524,\n",
       "           -0.0191, -0.0954,  0.0397, -0.0825, -0.0888,  0.0872,  0.0191, -0.0728,\n",
       "           -0.0430,  0.0034,  0.0496,  0.0875,  0.0195, -0.1207, -0.0384,  0.1234,\n",
       "           -0.0336, -0.1157, -0.0882, -0.0405,  0.0741,  0.0291,  0.0817,  0.1324,\n",
       "            0.0153,  0.0592,  0.0696,  0.0774,  0.1572,  0.0171,  0.0494,  0.0154,\n",
       "           -0.0443, -0.0007, -0.0363,  0.0989, -0.0582,  0.0144,  0.0400,  0.0698,\n",
       "           -0.0566, -0.0885,  0.0008, -0.0331,  0.1408,  0.0887,  0.0559, -0.0333,\n",
       "           -0.1113, -0.1884,  0.0102, -0.0333, -0.1205,  0.0596, -0.0234, -0.1455,\n",
       "            0.0598, -0.1568, -0.0203, -0.0970, -0.0001, -0.0757, -0.1645, -0.0250,\n",
       "           -0.1217,  0.0602, -0.0991, -0.0124, -0.0962,  0.0130,  0.0172,  0.0814,\n",
       "            0.0197, -0.1365, -0.1504,  0.1174, -0.1287, -0.0332,  0.1379, -0.1169,\n",
       "           -0.1334,  0.0008,  0.1251, -0.0285],\n",
       "          [ 0.0581,  0.0280,  0.1826,  0.0088, -0.0605, -0.0754,  0.0593, -0.0938,\n",
       "            0.0742, -0.1269,  0.0105, -0.0320, -0.0025, -0.0063, -0.1053, -0.0212,\n",
       "            0.1045, -0.0720,  0.0269, -0.1222,  0.0788,  0.0422,  0.0500,  0.0884,\n",
       "           -0.0616, -0.0575,  0.0125,  0.0037,  0.0553,  0.0438, -0.0291, -0.0689,\n",
       "           -0.0857,  0.0467, -0.0620,  0.0478,  0.1196, -0.1911, -0.0375,  0.0626,\n",
       "           -0.0653, -0.0886,  0.0274,  0.1257,  0.1576,  0.0962, -0.0763, -0.0187,\n",
       "            0.1515,  0.0915,  0.1097,  0.0732, -0.0320, -0.0531, -0.0607, -0.0296,\n",
       "           -0.0209, -0.0150, -0.0126,  0.0653, -0.0933, -0.1372,  0.1452,  0.1002,\n",
       "            0.0093, -0.2313,  0.0715, -0.0054,  0.0307,  0.0270, -0.0970, -0.1264,\n",
       "            0.0229, -0.0988,  0.1703, -0.1612,  0.0431,  0.0423,  0.0592, -0.0629,\n",
       "           -0.0649, -0.1924,  0.0811, -0.0092, -0.0048,  0.0379, -0.0829,  0.0493,\n",
       "           -0.0696,  0.1276, -0.0669,  0.0515,  0.1873, -0.1213, -0.0788,  0.1078,\n",
       "           -0.0852, -0.0794, -0.1112,  0.0677],\n",
       "          [-0.0041, -0.0882,  0.0232, -0.0509, -0.0124, -0.0946,  0.1161,  0.0553,\n",
       "           -0.0353, -0.0428, -0.0464, -0.0723,  0.0418,  0.0619, -0.0563, -0.1480,\n",
       "           -0.0269,  0.0537, -0.0147,  0.0621, -0.0483,  0.0766,  0.1372,  0.0556,\n",
       "           -0.0634,  0.0125, -0.0801,  0.1263, -0.1178,  0.0718, -0.0330, -0.1156,\n",
       "            0.0631,  0.0425, -0.1111,  0.1151, -0.1454,  0.0208,  0.0728,  0.0728,\n",
       "            0.0012,  0.0236, -0.0161, -0.0793,  0.0412,  0.0776,  0.0938, -0.0376,\n",
       "           -0.1394, -0.1514,  0.0361, -0.1127,  0.1118,  0.0761,  0.2129,  0.0584,\n",
       "            0.1559,  0.0651,  0.0694,  0.1338, -0.0412,  0.0217,  0.0555, -0.0791,\n",
       "           -0.0645,  0.1185,  0.0950,  0.0064, -0.0559,  0.0078,  0.0650,  0.0712,\n",
       "            0.0379, -0.1057, -0.1233,  0.0504, -0.1946, -0.1706, -0.0762, -0.0388,\n",
       "           -0.0061, -0.0039, -0.0737, -0.0150, -0.0344,  0.1097, -0.0521,  0.0079,\n",
       "            0.0006,  0.0797,  0.1536, -0.0094,  0.0323, -0.2353, -0.0511,  0.0212,\n",
       "            0.0524,  0.0753, -0.0958,  0.0291],\n",
       "          [-0.0849, -0.0765,  0.0488,  0.1003,  0.0020,  0.1745, -0.1784,  0.0384,\n",
       "           -0.0991, -0.0868, -0.0500,  0.0152,  0.0141,  0.1575,  0.0833, -0.0926,\n",
       "           -0.1223,  0.0021, -0.0903, -0.0230, -0.0445,  0.0625, -0.0897,  0.0326,\n",
       "            0.0738,  0.0036, -0.0414, -0.1385, -0.1127,  0.0105, -0.0986,  0.0617,\n",
       "            0.1653,  0.1522, -0.1347, -0.0329,  0.0112, -0.0558, -0.0056, -0.0638,\n",
       "           -0.1825, -0.0352, -0.0153, -0.0772, -0.0582,  0.0290, -0.0602,  0.1946,\n",
       "            0.1320, -0.1297,  0.1148,  0.1103, -0.1089, -0.0009, -0.1487, -0.0193,\n",
       "            0.1785, -0.1575,  0.1191, -0.0879,  0.1074,  0.0812, -0.0554,  0.0614,\n",
       "           -0.0423, -0.0024, -0.0590,  0.0312, -0.0602, -0.0382, -0.0609, -0.0795,\n",
       "            0.1432, -0.0973,  0.1031,  0.0514,  0.0952, -0.0854, -0.0753,  0.1062,\n",
       "            0.0302, -0.0223, -0.1178,  0.1209, -0.0201, -0.0644,  0.0791,  0.1052,\n",
       "           -0.0011, -0.0396,  0.1169,  0.0906, -0.0594,  0.0591,  0.0796,  0.1649,\n",
       "            0.0422,  0.0014,  0.0904,  0.0490],\n",
       "          [ 0.2067,  0.0719, -0.0898,  0.0777, -0.0969, -0.1363, -0.0446, -0.0833,\n",
       "           -0.0189,  0.0011, -0.0674, -0.1511,  0.1227,  0.1297,  0.0132,  0.0377,\n",
       "           -0.0199,  0.1446, -0.0392,  0.0773,  0.0490,  0.0678, -0.0202, -0.0824,\n",
       "            0.1034,  0.0217,  0.0455,  0.0634, -0.1911,  0.0131, -0.0332, -0.0220,\n",
       "            0.0830, -0.1386,  0.0942,  0.0756,  0.1230, -0.0601,  0.0825,  0.0204,\n",
       "            0.0007,  0.1134, -0.0855,  0.0095,  0.0097,  0.0349,  0.1328,  0.0637,\n",
       "            0.2027,  0.0867, -0.0636, -0.1173, -0.0260,  0.0433, -0.0330, -0.0118,\n",
       "           -0.0496,  0.0082, -0.0666,  0.0315, -0.0627,  0.0031, -0.1260,  0.0481,\n",
       "            0.0488,  0.0515, -0.1379, -0.0592,  0.0005, -0.0309,  0.1318,  0.1088,\n",
       "            0.0853,  0.1090,  0.1096, -0.1255, -0.0190, -0.1689, -0.1564,  0.0199,\n",
       "           -0.0234,  0.1412, -0.1594, -0.0918, -0.0058, -0.0616,  0.0707,  0.0257,\n",
       "            0.0236,  0.0257, -0.0485,  0.0578,  0.1225,  0.0178, -0.1525,  0.1456,\n",
       "            0.0179,  0.0077,  0.1229,  0.0664]], requires_grad=True)), ('output_linear.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0600,  0.1244, -0.0735, -0.0227,  0.1646,  0.0247,  0.0209,  0.0722,\n",
       "           0.0432,  0.0972], requires_grad=True))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
