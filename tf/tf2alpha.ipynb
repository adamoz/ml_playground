{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "59744/60000 [============================>.] - ETA: 0s - loss: 0.2934 - accuracy: 0.9141\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 12s 194us/sample - loss: 0.2935 - accuracy: 0.9140\n",
      "Epoch 2/5\n",
      "59808/60000 [============================>.] - ETA: 0s - loss: 0.1443 - accuracy: 0.9569\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.1442 - accuracy: 0.9570\n",
      "Epoch 3/5\n",
      "59808/60000 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9675\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 11s 184us/sample - loss: 0.1064 - accuracy: 0.9675\n",
      "Epoch 4/5\n",
      "59872/60000 [============================>.] - ETA: 0s - loss: 0.0885 - accuracy: 0.9730\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0885 - accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9766\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 11s 180us/sample - loss: 0.0735 - accuracy: 0.9766\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0797 - accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07973091734303162, 0.9768]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, callbacks=[cp_callback])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9c101ca630>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_OptionsDataset shapes: ((28, 28, 1), ()), types: (tf.uint8, tf.int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dataset['train'].map(convert_types).shuffle(10000).batch(32)\n",
    "mnist_test = dataset['test'].map(convert_types).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  320       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2769024   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 2,770,634\n",
      "Trainable params: 2,770,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image)\n",
    "        loss = loss_object(label, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, predictions)\n",
    "\n",
    "    \n",
    "# Pushing code to graph.\n",
    "@tf.function\n",
    "def test_step(image, label):\n",
    "    predictions = model(image)\n",
    "    t_loss = loss_object(label, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    return model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for step 2: ./tf_ckpts/ckpt-1\n",
      "Epoch 1, Loss: 0.1374327689409256, Accuracy: 95.88166809082031, Test Loss: 0.06837800145149231, Test Accuracy: 97.70999908447266\n",
      "Saved checkpoint for step 3: ./tf_ckpts/ckpt-2\n",
      "Epoch 2, Loss: 0.09150621294975281, Accuracy: 97.22750091552734, Test Loss: 0.060234107077121735, Test Accuracy: 98.04000091552734\n",
      "Saved checkpoint for step 4: ./tf_ckpts/ckpt-3\n",
      "Epoch 3, Loss: 0.06872385740280151, Accuracy: 97.90721893310547, Test Loss: 0.057813432067632675, Test Accuracy: 98.16667175292969\n",
      "Saved checkpoint for step 5: ./tf_ckpts/ckpt-4\n",
      "Epoch 4, Loss: 0.055405694991350174, Accuracy: 98.31541442871094, Test Loss: 0.05761345848441124, Test Accuracy: 98.22999572753906\n",
      "Epoch 5, Loss: 0.046451643109321594, Accuracy: 98.58466339111328, Test Loss: 0.058373551815748215, Test Accuracy: 98.26800537109375\n"
     ]
    }
   ],
   "source": [
    "last_loss = 999\n",
    "for epoch in range(5):\n",
    "    for image, label in mnist_train:\n",
    "        train_step(image, label)\n",
    "\n",
    "    for test_image, test_label in mnist_test:\n",
    "        test_step(test_image, test_label)\n",
    "    \n",
    "    ckpt.step.assign_add(1)\n",
    "    if test_loss.result() < last_loss:\n",
    "        last_loss = test_loss.result()\n",
    "        save_path = manager.save()\n",
    "        print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1, train_loss.result(),\n",
    "                           train_accuracy.result()*100,\n",
    "                           test_loss.result(),\n",
    "                           test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.save_weights('test.h5')\n",
    "model.load_weights('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tf_ckpts/ckpt-4'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manager.latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9c524acac8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.restore(manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = next(iter(mnist_test))\n",
    "result = model(data)\n",
    "np.mean(np.argmax(result.numpy(), axis=1) == labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(np.zeros([32, 28, 28, 1], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_ds = tf.data.Dataset.from_tensor_slices(train)\n",
    "mnist_ds = mnist_ds.shuffle(1000000).batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=102606, shape=(5, 28, 28), dtype=uint8, numpy=\n",
       " array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)>,\n",
       " <tf.Tensor: id=102607, shape=(5,), dtype=uint8, numpy=array([0, 5, 8, 2, 7], dtype=uint8)>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(mnist_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "def maybe_download():\n",
    "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
    "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
    "\n",
    "    return train_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/adam/.keras/datasets/iris_training.csv',\n",
       " '/home/adam/.keras/datasets/iris_test.csv')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maybe_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "irs_ds = tf.data.TextLineDataset('/home/adam/.keras/datasets/iris_training.csv').skip(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "irs_ds = irs_ds.shuffle(100).batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23831, shape=(5,), dtype=string, numpy=\n",
       "array([b'5.4,3.7,1.5,0.2,0', b'6.3,3.4,5.6,2.4,2', b'4.9,3.0,1.4,0.2,0',\n",
       "       b'6.4,2.7,5.3,1.9,2', b'6.0,2.9,4.5,1.5,1'], dtype=object)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(irs_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_TYPES = [[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "\n",
    "def _parse_line(line):\n",
    "    # Decode the line into its fields\n",
    "    fields = tf.io.decode_csv(line, record_defaults=CSV_TYPES)\n",
    "\n",
    "    # Pack the result into a dictionary\n",
    "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
    "\n",
    "    # Separate the label from the features\n",
    "    label = features.pop('Species')\n",
    "\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "irs_ds = tf.data.TextLineDataset('/home/adam/.keras/datasets/iris_training.csv').skip(1)\n",
    "irs_ds = irs_ds.map(_parse_line).shuffle(100).batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'PetalLength': <tf.Tensor: id=23886, shape=(5,), dtype=float32, numpy=array([4.5, 4.8, 4.8, 4.9, 1.3], dtype=float32)>,\n",
       "  'PetalWidth': <tf.Tensor: id=23887, shape=(5,), dtype=float32, numpy=array([1.5, 1.8, 1.8, 1.5, 0.3], dtype=float32)>,\n",
       "  'SepalLength': <tf.Tensor: id=23888, shape=(5,), dtype=float32, numpy=array([6.4, 6. , 5.9, 6.9, 5. ], dtype=float32)>,\n",
       "  'SepalWidth': <tf.Tensor: id=23889, shape=(5,), dtype=float32, numpy=array([3.2, 3. , 3.2, 3.1, 3.5], dtype=float32)>},\n",
       " <tf.Tensor: id=23890, shape=(5,), dtype=int32, numpy=array([1, 2, 1, 1, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(irs_ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
